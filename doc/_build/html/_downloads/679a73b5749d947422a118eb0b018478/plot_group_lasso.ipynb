{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\nMulti-subject joint source localization with multi-task models\n==============================================================\n\nThe aim of this tutorial is to show how to leverage functional similarity\nacross subjects to improve source localization. For that purpose we use the\nthe high frequency SEF MEG dataset of (Nurminen et al., 2017) which provides\nMEG and MRI data for two subjects.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Author: Hicham Janati (hicham.janati@inria.fr)\n#\n# License: BSD (3-clause)\n\nimport mne\nimport os\nimport os.path as op\nfrom mne.parallel import parallel_func\nfrom mne.datasets import hf_sef\nfrom matplotlib import pyplot as plt\n\nfrom groupmne import group_model\nfrom groupmne.inverse import compute_group_inverse"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Download and process MEG data\n-----------------------------\n\nWe need the raw data to estimate the noise covariance\nsince only average MEG data (and MRI) are provided in \"evoked\".\nThe data will be downloaded in the same location\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "_ = hf_sef.data_path(\"raw\")\ndata_path = hf_sef.data_path(\"evoked\")\nmeg_path = data_path + \"/MEG/\"\n\ndata_path = op.expanduser(data_path)\nsubjects_dir = data_path + \"/subjects/\"\nos.environ['SUBJECTS_DIR'] = subjects_dir\n\nraw_name_s = [meg_path + s for s in [\"subject_a/sef_right_raw.fif\",\n              \"subject_b/hf_sef_15min_raw.fif\"]]\n\n\ndef process_meg(raw_name):\n    raw = mne.io.read_raw_fif(raw_name)\n    events = mne.find_events(raw)\n\n    event_id = dict(hf=1)  # event trigger and conditions\n    tmin = -0.05  # start of each epoch (50ms before the trigger)\n    tmax = 0.3  # end of each epoch (300ms after the trigger)\n    baseline = (None, 0)  # means from the first instant to t = 0\n    epochs = mne.Epochs(raw, events, event_id, tmin, tmax, proj=True,\n                        baseline=baseline)\n    return epochs\n\n\nepochs_s = [process_meg(raw_name) for raw_name in raw_name_s]\nevoked_s = [ep.average() for ep in epochs_s]\n\n# compute noise covariance (takes a few minutes)\nnoise_cov_s = []\nfor subj, ep in zip([\"a\", \"b\"], epochs_s):\n    cov_fname = meg_path + f\"subject_{subj}/sef-cov.fif\"\n    if os.path.exists(cov_fname):\n        cov = mne.read_cov(cov_fname)\n    else:\n        cov = mne.compute_covariance(ep, tmin=None, tmax=0.)\n        mne.write_cov(cov_fname, cov)\n    noise_cov_s.append(cov)\n\n\nf, axes = plt.subplots(1, 2, sharey=True)\nfor ax, ev, nc, ll in zip(axes.ravel(), evoked_s, noise_cov_s, [\"a\", \"b\"]):\n    picks = mne.pick_types(ev.info, meg=\"grad\")\n    ev.plot(picks=picks, axes=ax, noise_cov=nc, show=False)\n    ax.set_title(\"Subject %s\" % ll, fontsize=15)\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Source and forward modeling\n---------------------------\nTo guarantee an alignment across subjects, we start by\ncomputing (or reading if available) the source space of the average\nsubject of freesurfer `fsaverage`\nIf fsaverage is not available, it will be fetched to the data_path\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "resolution = 4\nspacing = \"ico%d\" % resolution\nsrc_ref = group_model.get_src_reference(spacing=spacing,\n                                        subjects_dir=subjects_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# the function group_model.compute_fwd morphs the source space src_ref to the\n# surface of each subject by mapping the sulci and gyri patterns\n# and computes their forward operators\n\nsubjects = [\"subject_a\", \"subject_b\"]\ntrans_fname_s = [meg_path + \"%s/sef-trans.fif\" % s for s in subjects]\nbem_fname_s = [subjects_dir + \"%s/bem/%s-5120-bem-sol.fif\" % (s, s)\n               for s in subjects]\nn_jobs = 2\nparallel, run_func, _ = parallel_func(group_model.compute_fwd, n_jobs=n_jobs)\n\nfwds = parallel(run_func(s, src_ref, info, trans, bem,  mindist=3)\n                for s, info, trans, bem in zip(subjects, raw_name_s,\n                                               trans_fname_s, bem_fname_s))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can now compute the data of the inverse problem.\n`group_info` is a dictionary that contains the selected channels and the\nalignment maps between src_ref and the subjects which are required if you\nwant to plot source estimates on the brain surface of each subject.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "gains, M, group_info = \\\n    group_model.compute_inv_data(fwds, src_ref, evoked_s, noise_cov_s,\n                                 ch_type=\"grad\", tmin=0.02, tmax=0.04)\nprint(\"(# subjects, # channels, # sources) = \", gains.shape)\nprint(\"(# subjects, # channels, # time points) = \", M.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Inverse problem\n---------------\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "stcs, log = compute_group_inverse(gains, M, group_info, method=\"grouplasso\",\n                                  depth=0.9, alpha=0.1, return_stc=True,\n                                  n_jobs=4)\nt = 0.025\nt_idx = stcs[0].time_as_index(t)\nfor stc in stcs:\n    m = abs(stc.data[:group_info[\"n_sources\"][0], t_idx]).max()\n    print(m)\n    surfer_kwargs = dict(\n        clim=dict(kind='value', pos_lims=[0., 0.25 * m, m]),\n        hemi='lh', subjects_dir=subjects_dir, views='lateral',\n        initial_time=t, time_unit='s', size=(800, 800),\n        smoothing_steps=5)\n    stc.plot(**surfer_kwargs)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}